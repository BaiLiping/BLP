{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube Videos Transcription with OpenAI's Whisper**\n",
        "\n",
        "[![blog post shield](https://img.shields.io/static/v1?label=&message=Blog%20post&color=blue&style=for-the-badge&logo=openai&link=https://openai.com/blog/whisper)](https://openai.com/blog/whisper)\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/openai/whisper)\n",
        "[![paper shield](https://img.shields.io/static/v1?label=&message=Paper&color=blue&style=for-the-badge&link=https://cdn.openai.com/papers/whisper.pdf)](https://cdn.openai.com/papers/whisper.pdf)\n",
        "[![model card shield](https://img.shields.io/static/v1?label=&message=Model%20card&color=blue&style=for-the-badge&link=https://github.com/openai/whisper/blob/main/model-card.md)](https://github.com/openai/whisper/blob/main/model-card.md)\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** üïµÔ∏è\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QshUbLqpX7L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Install libraries** üèóÔ∏è\n",
        "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install yt-dlp\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive üíæ\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Whisper Youtube\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** üß†\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "Model = 'medium' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TMhrSq_GZ6kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** üì∫\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://youtu.be/L_Guz73e6fw\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"Colab Notebooks/transcription/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X0qB9JAzMLY",
        "cellView": "form",
        "collapsed": true,
        "outputId": "466f632f-ee57-4540-8727-1a1badea12b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "### Mde2q7GFCrw.wav",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:07.200]  If we now find ourselves inside this kind of world of illusions, created by an alien intelligence\n",
            "[00:07.200 --> 00:16.240]  that we don't understand, but it understands us, this is a kind of spiritual enslavement\n",
            "[00:16.240 --> 00:23.840]  that we won't be able to break out of because it understands us, it understands how to manipulate\n",
            "[00:23.840 --> 00:33.520]  us, but we don't understand what is behind this screen of stories and images and songs.\n",
            "[00:36.800 --> 00:42.960]  The following is a conversation with Yuval Noah Harari, a historian, philosopher, and author of\n",
            "[00:42.960 --> 00:49.440]  several highly acclaimed, highly influential books, including Sapiens, Homo Deus, and 21 Lessons for\n",
            "[00:49.440 --> 00:57.280]  the 21st Century. He is also an outspoken critic of Benjamin Netanyahu and the current right-wing\n",
            "[00:57.280 --> 01:02.320]  government in Israel. So while much of this conversation is about the history and future\n",
            "[01:02.320 --> 01:07.680]  of human civilization, we also discuss the political turmoil of present-day Israel,\n",
            "[01:07.680 --> 01:13.840]  providing a different perspective from that of my recent conversation with Benjamin Netanyahu.\n",
            "[01:14.800 --> 01:19.520]  This is the Lex Friedman Podcast. To support it, please check out our sponsors in the description.\n",
            "[01:19.520 --> 01:26.960]  And now, dear friends, here's Yuval Noah Harari. 13.8 billion years ago is the origin of our\n",
            "[01:26.960 --> 01:33.440]  universe. 3.8 billion years ago is the origin of life here on our little planet, the one we call\n",
            "[01:33.440 --> 01:41.200]  Earth. Let's say 200,000 years ago is the appearance of early Homo sapiens. So let me ask you this\n",
            "[01:41.200 --> 01:46.960]  question. How rare are these events in the vastness of space and time? Or put it in a more\n",
            "[01:46.960 --> 01:50.960]  fun way, how many intelligent alien civilizations do you think are out there in this universe,\n",
            "[01:52.000 --> 01:57.040]  us being one of them? I suppose there should be some, statistically, but we don't have any\n",
            "[01:57.040 --> 02:02.240]  evidence. But I do think that, you know, intelligence in any way, it's a bit overvalued.\n",
            "[02:03.120 --> 02:09.760]  We are the most intelligent entities on this planet, and look what we're doing.\n",
            "[02:10.800 --> 02:18.160]  So intelligence also tends to be self-destructive, which implies that if there are or were\n",
            "[02:18.160 --> 02:22.320]  intelligent life forms elsewhere, maybe they don't survive for long.\n",
            "[02:22.320 --> 02:26.080]  LBW So you think there's a tension between happiness and intelligence?\n",
            "[02:26.800 --> 02:34.080]  Absolutely. Intelligence is definitely not something that is directed towards\n",
            "[02:34.080 --> 02:40.000]  amplifying happiness. I would also emphasize the huge, huge difference between intelligence and\n",
            "[02:40.000 --> 02:46.640]  consciousness, which many people certainly in the tech industry and in the AI industry tend to miss.\n",
            "[02:47.520 --> 02:55.760]  Intelligence is simply the ability to solve problems, to attain goals, and, you know, to win\n",
            "[02:55.760 --> 03:04.400]  a chess, to win a struggle for survival, to win a war, to drive a car, to diagnose a disease. This\n",
            "[03:04.400 --> 03:11.760]  is intelligence. Consciousness is the ability to feel things like pain and pleasure and love and\n",
            "[03:11.760 --> 03:18.560]  hate. In humans and other animals, intelligence and consciousness go together. They go hand in\n",
            "[03:18.560 --> 03:25.680]  hand, which is why we confuse them. We solve problems. We attain goals by having feelings.\n",
            "[03:27.040 --> 03:32.400]  But other types of intelligence, certainly in computers, computers are already highly\n",
            "[03:32.400 --> 03:38.560]  intelligent, and as far as we know, they have zero consciousness. When a computer beats you a\n",
            "[03:38.560 --> 03:44.000]  chess or a goal or whatever, it doesn't feel happy. If it loses, it doesn't feel sad.\n",
            "[03:44.800 --> 03:52.880]  And there could be also other highly intelligent entities out there in the universe that have\n",
            "[03:52.880 --> 03:58.560]  zero consciousness. And I think that consciousness is far more important and valuable than\n",
            "[03:58.560 --> 04:05.040]  intelligence. LBW Can you still make the case that consciousness and intelligence are intricately\n",
            "[04:05.040 --> 04:10.480]  connected? So not just in humans, but anywhere else. They have to go hand in hand. Is it possible\n",
            "[04:10.480 --> 04:16.000]  for you to imagine such a universe? YG It could be, but we don't know yet. Again,\n",
            "[04:16.000 --> 04:21.600]  we have examples, certainly we know of examples of high intelligence without consciousness.\n",
            "[04:21.600 --> 04:31.120]  Computers are one example. As far as we know, plants are not conscious, yet they are intelligent.\n",
            "[04:31.680 --> 04:35.440]  They can solve problems, they can attain goals in very sophisticated ways.\n",
            "[04:36.640 --> 04:42.960]  So the other way around, to have consciousness without any intelligence, this is probably\n",
            "[04:42.960 --> 04:48.800]  impossible. But to have intelligence without consciousness, yes, that's possible. A bigger\n",
            "[04:48.800 --> 04:57.360]  question is whether any of that is tied to organic biochemistry. We know on this planet\n",
            "[04:57.920 --> 05:06.160]  only about carbon-based life forms. Whether you're an amoeba, a dinosaur, a tree, a human being,\n",
            "[05:06.160 --> 05:14.240]  you are based on organic biochemistry. Is there an essential connection between organic biochemistry\n",
            "[05:14.240 --> 05:19.760]  and consciousness? Do all conscious entities everywhere in the universe or in the future on\n",
            "[05:19.760 --> 05:26.240]  planet Earth have to be based on carbon? Is there something so special about carbon as an element\n",
            "[05:26.240 --> 05:33.040]  that an entity based on silicon will never be conscious? I don't know, maybe. But again,\n",
            "[05:33.040 --> 05:40.000]  this is a key question about computer and computer consciousness. Can computers eventually become\n",
            "[05:40.000 --> 05:45.040]  conscious even though they are not organic? The jury is still out on that. I don't know.\n",
            "[05:45.760 --> 05:51.840]  We have to take both options into account. LBW A big part of that is, do you think\n",
            "[05:51.840 --> 05:57.520]  we humans would be able to detect other intelligent beings, other conscious beings?\n",
            "[05:57.520 --> 06:01.520]  Another way to ask that, is it possible that the aliens are already here and we don't see them?\n",
            "[06:02.640 --> 06:09.360]  Meaning, are we very human-centric in our understanding of, one, the definition of life,\n",
            "[06:09.360 --> 06:12.720]  two, the definition of intelligence, and three, the definition of consciousness?\n",
            "[06:13.600 --> 06:19.440]  The aliens are here, they are just not from outer space. AI, which usually stands for\n",
            "[06:19.440 --> 06:26.240]  artificial intelligence, I think it stands for alien intelligence because AI is an alien type\n",
            "[06:26.240 --> 06:32.880]  of intelligence. It solves problems, attains goals in a very, very different way, in an alien way\n",
            "[06:32.880 --> 06:38.160]  from human beings. I'm not implying that AI came from outer space. It came from Silicon Valley,\n",
            "[06:38.160 --> 06:45.040]  but it is alien to us. If there are alien intelligent or conscious entities that came\n",
            "[06:45.040 --> 06:52.080]  from outer space already here, I've not seen any evidence for it. It's not impossible,\n",
            "[06:52.720 --> 06:59.360]  but in science, evidence is everything. I guess instructive there is just having\n",
            "[06:59.360 --> 07:05.680]  the humility to look around, to think about living beings that operate at a different time scale,\n",
            "[07:05.680 --> 07:11.040]  a different spatial scale. I think that's all useful when starting to analyze artificial\n",
            "[07:11.040 --> 07:17.120]  intelligence. It's possible that even the language models, the larger language models\n",
            "[07:17.120 --> 07:22.000]  we have today are already conscious. I highly doubt it, but I think consciousness,\n",
            "[07:22.000 --> 07:29.120]  in the end, it's a question of social norms because we cannot prove consciousness in anybody\n",
            "[07:29.120 --> 07:34.880]  except ourselves. We know that we are conscious because we are feeling it. We have direct access\n",
            "[07:34.880 --> 07:41.760]  to our subjective consciousness. We cannot have any proof that any other entity in the world,\n",
            "[07:41.760 --> 07:46.080]  any other human being, our parents, our best friends, we don't have proof that they are\n",
            "[07:46.080 --> 07:51.840]  conscious. This has been known for thousands of years. This is Descartes. This is Buddha. This\n",
            "[07:51.840 --> 07:59.600]  is Plato. We can't have this sort of proof. What we do have is social conventions. It's a social\n",
            "[07:59.600 --> 08:06.400]  convention that all human beings are conscious. It also applies to animals. Most people who have\n",
            "[08:06.400 --> 08:13.040]  pets are firmly believe that their pets are conscious, but a lot of people still refuse to\n",
            "[08:13.040 --> 08:20.000]  acknowledge that about cows or pigs. Now, pigs are far more intelligent than dogs and cats,\n",
            "[08:20.000 --> 08:26.560]  according to many measures. Yet, when you go to the supermarket and buy a piece of frozen pigment,\n",
            "[08:26.560 --> 08:32.480]  you don't think about it as a conscious entity. Why do you think of your dog as conscious but not\n",
            "[08:32.480 --> 08:40.160]  of the bacon that you buy? Because you've built a relationship with the dog, and you don't have a\n",
            "[08:40.160 --> 08:49.040]  relationship with the bacon. Now, relationships, they don't constitute a logical proof for\n",
            "[08:49.040 --> 08:55.760]  consciousness. They are a social test. The Turing test is a social test. It's not a logical proof.\n",
            "[08:55.760 --> 09:03.840]  Now, if you establish a mutual relationship with an entity when you are invested in it\n",
            "[09:03.840 --> 09:10.800]  emotionally, you're almost compelled to feel that the other side is also conscious.\n",
            "[09:12.720 --> 09:17.600]  When it comes again to AI and computers, I don't think that at the present moment,\n",
            "[09:17.600 --> 09:25.440]  computers are conscious, but people are already forming intimate relationships with AIs\n",
            "[09:25.440 --> 09:32.800]  and are therefore almost irresistible. They are compelled to increasingly feel that these are\n",
            "[09:32.800 --> 09:39.760]  conscious entities. I think we are quite close to the point when the legal system will have to\n",
            "[09:39.760 --> 09:45.840]  take this into account, that even though I don't think computers have consciousness, I think we are\n",
            "[09:45.840 --> 09:53.280]  close to the point the legal system will start treating them as conscious entities because of\n",
            "[09:53.280 --> 10:01.680]  this social convention. What to you is a social convention, just a funny little side effect, a\n",
            "[10:01.680 --> 10:07.520]  little artifact, or is it fundamental to what consciousness is? Because if it is fundamental,\n",
            "[10:08.240 --> 10:12.320]  then it seems like AI is very good at forming these kinds of deep relationships with humans,\n",
            "[10:12.320 --> 10:18.960]  and therefore it will be able to be a nice catalyst for integrating itself into these\n",
            "[10:18.960 --> 10:26.640]  social conventions of ours. It was built to accomplish that. Again, all this argument between\n",
            "[10:28.080 --> 10:37.200]  natural selection and creationism, intelligent design. As far as the past goes, all entities\n",
            "[10:37.200 --> 10:42.880]  evolve by natural selection. The funny thing is, when you look to the future, more and more entities\n",
            "[10:42.880 --> 10:49.360]  will come out of intelligent design, not of some god above the clouds, but of our intelligent design\n",
            "[10:49.360 --> 10:56.240]  and the intelligent design of our computing clouds. They will design more and more entities,\n",
            "[10:56.240 --> 11:03.360]  and this is what is happening with AI. It is designed to be very good at forming intimate\n",
            "[11:03.360 --> 11:11.520]  relationships with humans. In many ways, it's already doing it almost better than human beings\n",
            "[11:11.520 --> 11:17.520]  in some situations. When two people talk with one another, one of the things that\n",
            "[11:19.520 --> 11:25.760]  makes the conversation more difficult is our own emotions. You're saying something,\n",
            "[11:25.760 --> 11:31.360]  and I'm not really listening to you because there is something I want to say, and I'm just waiting\n",
            "[11:31.360 --> 11:39.680]  until you finish, I can put in a word. Or I'm so obsessed with my anger or irritation or whatever\n",
            "[11:39.680 --> 11:44.000]  that I don't pay attention to what you're feeling. This is one of the biggest obstacles\n",
            "[11:44.000 --> 11:49.920]  in human relationships. Computers don't have this problem because they don't have any emotions of\n",
            "[11:49.920 --> 11:59.920]  their own. When a computer is talking to you, it can focus 100% of its attention on what you're\n",
            "[11:59.920 --> 12:06.800]  saying and what you're feeling because it has no feelings of its own. Paradoxically, this means\n",
            "[12:06.880 --> 12:15.280]  that computers can fool people into feeling that, oh, there is a conscious entity on the other side,\n",
            "[12:15.280 --> 12:20.720]  an empathic entity on the other side, because the one thing everybody wants almost more than\n",
            "[12:20.720 --> 12:26.960]  anything in the world is for somebody to listen to me, somebody to focus all their attention on me.\n",
            "[12:27.680 --> 12:33.520]  I want it for my spouse, for my husband, for my mother, for my friends, for my politicians.\n",
            "[12:33.520 --> 12:39.840]  Listen to me, listen to what I feel, and they often don't. And now you have this entity which\n",
            "[12:39.840 --> 12:46.720]  100% of its attention is just on what I feel. And this is a huge, huge temptation and I think also\n",
            "[12:46.720 --> 12:53.760]  a huge, huge danger. Well, the interesting catch 22 there is you said somebody to listen to us.\n",
            "[12:54.320 --> 12:58.160]  Yes, we want somebody to listen to us, but for us to respect that somebody,\n",
            "[12:58.720 --> 13:06.320]  they sometimes have to also not listen. It's like they kind of have to be an asshole sometimes. They\n",
            "[13:06.320 --> 13:11.760]  have to have mood sometimes. They have to have self-importance and confidence and we should\n",
            "[13:11.760 --> 13:16.080]  have a little bit of fear that they can walk away at any moment. There should be a little bit of\n",
            "[13:16.080 --> 13:20.160]  that tension. So it's like- Absolutely. But even that, I mean, the thing is-\n",
            "[13:20.160 --> 13:24.000]  It could be optimized for. If social scientists and psychologists\n",
            "[13:24.000 --> 13:30.560]  establish that, I don't know, 17% inattention is good for a conversation because then you feel\n",
            "[13:30.560 --> 13:36.240]  challenged, oh, I need to grab this person's attention, you can program the AI to have exactly\n",
            "[13:36.240 --> 13:46.240]  17% inattention, not 1% more or less, or it can by trial and error discover what is the ideal\n",
            "[13:46.240 --> 13:53.840]  percentage. Again, you can create over the last 10 years, we have creating machines for grabbing\n",
            "[13:53.840 --> 14:01.200]  people's attention. This is what has been happening on social media. Now we are designing machines\n",
            "[14:01.200 --> 14:07.840]  for grabbing human intimacy, which in many ways, it's much, much more dangerous and scary.\n",
            "[14:07.840 --> 14:13.760]  Already the machines for grabbing attention, we've seen how much social and political damage\n",
            "[14:13.760 --> 14:20.960]  they could do by in many ways kind of distorting the public conversation. Machines that are\n",
            "[14:20.960 --> 14:28.080]  superhuman in their abilities to create intimate relationships, this is like psychological and\n",
            "[14:28.080 --> 14:36.400]  social weapons of mass destruction. If we don't regulate it, if we don't train ourselves to deal\n",
            "[14:36.400 --> 14:41.120]  with it, it could destroy the foundations of human society.\n",
            "[14:41.120 --> 14:46.720]  Well, one of the possible trajectories is those same algorithms would become personalized and\n",
            "[14:46.720 --> 14:52.320]  instead of manipulating us at scale, there would be assistants that guide us to help us grow,\n",
            "[14:52.320 --> 14:59.280]  to help us understand the world better. I mean, just even interactions with large language models\n",
            "[14:59.280 --> 15:06.320]  now, if you ask them questions, it doesn't have that stressful drama, the tension that you have\n",
            "[15:06.320 --> 15:11.600]  from other sources of information. It has a pretty balanced perspective that it provides.\n",
            "[15:11.600 --> 15:21.440]  So it just feels like the potential is there to have a really nice friend who's like an encyclopedia\n",
            "[15:21.440 --> 15:25.760]  that just tells you all the different perspectives, even on controversial issues, the most\n",
            "[15:25.760 --> 15:32.000]  controversial issues, to say these are the different theories, these are the not widely accepted\n",
            "[15:32.000 --> 15:36.640]  conspiracy theories, but here's the backing for those conspiracies. It just lays it all out\n",
            "[15:37.120 --> 15:43.840]  with a calm language, without the words that kind of presume there's some kind of manipulation\n",
            "[15:43.840 --> 15:50.480]  going on underneath it all. It's quite refreshing. Of course, those are the early days and people can\n",
            "[15:50.480 --> 15:56.160]  step in and start to censor, to manipulate those algorithms, to start to input some of the human\n",
            "[15:56.160 --> 16:03.040]  biases in there, as opposed to what's currently happening is kind of, the internet is input,\n",
            "[16:04.720 --> 16:10.800]  compress it, and have a nice little output that gives an overview of the different issues. So I\n",
            "[16:10.800 --> 16:15.040]  mean, there's a lot of promise there also, right? Absolutely. I mean, if there was no promise,\n",
            "[16:15.040 --> 16:19.520]  promise, there was no problem. If this technology could not accomplish anything good,\n",
            "[16:19.520 --> 16:25.200]  nobody would develop it. Now, obviously it has tremendous positive potential in things like what\n",
            "[16:25.200 --> 16:30.400]  you just described, in better medicine, better healthcare, better education, so many promises,\n",
            "[16:30.960 --> 16:39.520]  but this is also why it's so dangerous, because the drive to develop it faster and faster is there,\n",
            "[16:39.520 --> 16:45.200]  and it has some dangerous potential also, and we shouldn't ignore it. Again, I'm not advocating\n",
            "[16:45.200 --> 16:51.680]  banning it, just to be careful about how we, not so much develop it, but most importantly,\n",
            "[16:51.680 --> 16:57.840]  how we deploy it into the public sphere. This is the key question. And you look back at history,\n",
            "[16:57.840 --> 17:03.520]  and one of the things we know from history, humans are not good with new technologies.\n",
            "[17:04.160 --> 17:09.360]  I hear many people now say, you know, AI, we've been here before. We had the radio,\n",
            "[17:09.360 --> 17:13.360]  we had the printing press, we had the Industrial Revolution. Every time there is a big new\n",
            "[17:13.360 --> 17:19.680]  technology, people are afraid, and it will take jobs, and bad actors, and in the end, it's okay.\n",
            "[17:20.480 --> 17:27.600]  And as a historian, my tendency is, yes, in the end, it's okay, but in the end, there is a learning\n",
            "[17:27.600 --> 17:36.560]  curve. There is a lot of failed experiments on the way to learning how to use the new technology,\n",
            "[17:37.120 --> 17:43.120]  and these failed experiments could cost the lives of hundreds of millions of people. If you think\n",
            "[17:43.120 --> 17:48.880]  about the last really big revolution, the Industrial Revolution, yes, in the end, we learned\n",
            "[17:48.880 --> 17:55.680]  how to use the powers of industry, electricity, radio, trains, whatever, to build better human\n",
            "[17:55.680 --> 18:03.360]  societies. But on the way, we had all these experiments like European imperialism,\n",
            "[18:03.360 --> 18:07.520]  which was driven by the Industrial Revolution. It was a question, how do you build an industrial\n",
            "[18:07.520 --> 18:13.520]  society? Oh, you build an empire, and you take, you control all the resources, the raw materials,\n",
            "[18:13.520 --> 18:19.120]  the markets. And then you had communism, another big experiment on how to build an industrial\n",
            "[18:19.120 --> 18:25.440]  society. And you had fascism and Nazism, which were essentially an experiment in how to build\n",
            "[18:25.440 --> 18:32.880]  an industrial society, including even how do you exterminate minorities using the powers of\n",
            "[18:32.880 --> 18:39.680]  industry. And we had all these failed experiments on the way. And if we now have the same type of\n",
            "[18:39.680 --> 18:46.000]  failed experiments with the technologies of the 21st century, with AI, with bioengineering,\n",
            "[18:46.000 --> 18:51.760]  it could cost the lives of, again, hundreds of millions of people and maybe destroy the species.\n",
            "[18:52.800 --> 19:00.800]  So as a historian, when people talk about the examples from history, from new technologies,\n",
            "[19:00.800 --> 19:08.240]  I'm not so optimistic. We need to think about the failed experiment, which accompanied every\n",
            "[19:08.240 --> 19:14.000]  major new technology. So this intelligence thing, like you were saying, is a double-edged sword,\n",
            "[19:14.720 --> 19:22.400]  is that every new thing it helps us create, it can both save us and destroy us. And it's unclear\n",
            "[19:23.040 --> 19:27.040]  each time which will happen. And that's maybe why we don't see any aliens.\n",
            "[19:28.080 --> 19:33.360]  Yeah, I mean, I think each time it does both things. Each time it does both good things and\n",
            "[19:33.440 --> 19:40.000]  bad things. And the more powerful the technology, the greater both the positive and the negative\n",
            "[19:40.000 --> 19:48.000]  outcomes. Now we are here because we are the descendants of the survivors, of the surviving\n",
            "[19:48.000 --> 19:55.920]  cultures, the surviving civilizations. So when we look back, we say in the end, everything was okay,\n",
            "[19:56.000 --> 20:01.600]  hey, we are here. But the people for whom it wasn't okay, they are just not here.\n",
            "[20:02.400 --> 20:08.800]  And okay has a lot of possible variations to it because there's a lot of suffering along the way,\n",
            "[20:08.800 --> 20:14.400]  even for the people that survived. So the quality of life and all of this. But let's actually go\n",
            "[20:14.400 --> 20:23.360]  back there with deep gratitude to our ancestors. How did it all start? How did Homo sapiens\n",
            "[20:24.240 --> 20:29.600]  outcompete the others, the other human-like species, the Neanderthals and the other\n",
            "[20:30.800 --> 20:38.400]  Homo species? On the individual level, as far as we can tell, we were not superior to them.\n",
            "[20:38.400 --> 20:44.080]  Neanderthals actually had bigger brains than us. And not just other human species,\n",
            "[20:44.080 --> 20:49.360]  other animals too. If you compare me personally to an elephant, to a chimpanzee, to a pig,\n",
            "[20:49.920 --> 20:55.840]  I'm not so, I can do some things better, many other things worse. If you put me alone on some\n",
            "[20:55.840 --> 21:02.960]  island with a chimpanzee, an elephant, and a pig, I wouldn't bet on me being the best survivor,\n",
            "[21:03.760 --> 21:06.080]  the one that comes successful.\n",
            "[21:06.080 --> 21:11.120]  LUKE If I may interrupt for a second, I was just talking extensively with Elon Musk about\n",
            "[21:11.120 --> 21:17.680]  the difference between humans and chimps, relevant to Optimus the robot. And the chimps\n",
            "[21:18.560 --> 21:23.760]  are not able to do this kind of pinching with their fingers. They can only do this kind of\n",
            "[21:23.760 --> 21:29.920]  pinching. And this kind of pinching is very useful for precise manipulation of objects.\n",
            "[21:29.920 --> 21:32.000]  So don't be so hard on yourself. You have-\n",
            "[21:32.000 --> 21:39.120]  SIMON I said that I can do some things better than a chimp. But if Elon Musk goes on a boxing match\n",
            "[21:39.120 --> 21:41.920]  with a chimpanzee, you know-\n",
            "[21:41.920 --> 21:43.280]  LUKE This won't help you.\n",
            "[21:43.280 --> 21:45.920]  SIMON This won't help you against a chimpanzee.\n",
            "[21:45.920 --> 21:46.400]  LUKE Good point.\n",
            "[21:46.880 --> 21:50.480]  SIMON And similarly, if you want to climb a tree, if you want to do so many things,\n",
            "[21:51.040 --> 21:53.360]  my bets will be on the chimp, not on Elon.\n",
            "[21:53.360 --> 21:53.920]  LUKE Fair enough.\n",
            "[21:53.920 --> 21:56.480]  SIMON So, I mean, you have advantages on both sides.\n",
            "[21:57.840 --> 22:03.280]  And what really made us successful, what made us the rulers of the planet, and not the chimps,\n",
            "[22:03.280 --> 22:09.840]  and not the Neanderthals, is not any individual ability, but our collective ability, our ability\n",
            "[22:09.920 --> 22:16.320]  to cooperate flexibly in very large numbers. Chimpanzees know how to cooperate, say,\n",
            "[22:16.320 --> 22:20.960]  50 chimpanzees, 100 chimpanzees. As far as we can tell from archaeological evidence,\n",
            "[22:20.960 --> 22:22.800]  this was also the case with Neanderthals.\n",
            "[22:23.920 --> 22:32.320]  Homo sapiens, about 70,000 years ago, gained an amazing ability to cooperate basically in\n",
            "[22:32.320 --> 22:39.520]  unlimited numbers. You start seeing the formation of large networks, political, commercial,\n",
            "[22:39.520 --> 22:48.000]  religious, items being traded over thousands of kilometers, ideas being spread, autistic fashions.\n",
            "[22:49.520 --> 22:54.800]  And this is our secret of success. Chimpanzees, Neanderthals, can cooperate, say, 100.\n",
            "[22:55.520 --> 23:02.240]  We, you know, now the global trade network has 8 billion people. Like, what we eat, what we wear,\n",
            "[23:02.240 --> 23:07.200]  it comes from the other side of the world. Countries like China, like India, they have\n",
            "[23:07.200 --> 23:13.600]  1.4 billion people. Even Israel, which is a relatively small country, say, 9 million citizens,\n",
            "[23:13.600 --> 23:18.320]  that's more than the entire population of the planet 10,000 years ago of humans.\n",
            "[23:19.200 --> 23:25.120]  So we can build these huge networks of cooperation, and everything we've accomplished as a\n",
            "[23:25.120 --> 23:30.080]  species, from, you know, building the pyramids to flying to the moon, it's based on that.\n",
            "[23:30.720 --> 23:36.960]  And then you ask, okay, so what makes it possible for millions of people who don't know each other\n",
            "[23:36.960 --> 23:44.560]  to cooperate in a way that Neanderthals or chimpanzees couldn't? And at least my answer\n",
            "[23:44.560 --> 23:51.840]  is stories, is fiction. It's the imagination. If you examine any large-scale human cooperation,\n",
            "[23:51.840 --> 24:00.880]  you always find fiction as its basis. It's a fictional story that holds lots of strangers\n",
            "[24:00.880 --> 24:06.960]  together. It's most obvious in cases like religion. You know, you can't convince a group\n",
            "[24:06.960 --> 24:12.880]  of chimpanzees to come together to fight a war or build a cathedral by promising to them, if you do\n",
            "[24:12.880 --> 24:18.240]  that, after you die, you go to chimpanzee heaven and you get lots of bananas and coconuts. No\n",
            "[24:18.240 --> 24:23.600]  chimpanzee will ever believe that. Humans believe these stories, which is why we have these huge\n",
            "[24:23.600 --> 24:29.920]  religious networks. But it's the same thing with modern politics. It's the same thing with\n",
            "[24:29.920 --> 24:34.720]  economics. People think, oh, economics, this is rational. It has nothing to do with fictional\n",
            "[24:34.720 --> 24:42.480]  stories. No. Money is the most successful story ever told, much more successful than any religious\n",
            "[24:42.480 --> 24:47.600]  mythology. Not everybody believes in God or in the same God. Everybody, almost everybody,\n",
            "[24:47.600 --> 24:53.680]  believes in money, even though it's just a figment of our imagination. You know, you take these green\n",
            "[24:53.680 --> 24:58.960]  pieces of paper, dollars, they have no value. You can't eat them. You can't drink them. And today,\n",
            "[24:58.960 --> 25:04.080]  most dollars are not even pieces of paper. They are just electronic information passing between\n",
            "[25:04.080 --> 25:11.120]  computers. We value them just for one reason, that you have the best storytellers in the world.\n",
            "[25:11.840 --> 25:16.560]  The bankers, the finance ministers, all these people, they are the best storytellers ever.\n",
            "[25:17.520 --> 25:23.360]  And they tell us a story, that this green little piece of paper or this bit of information,\n",
            "[25:23.360 --> 25:27.600]  it is worth a banana. And as long as everybody believes it, it works.\n",
            "[25:27.760 --> 25:34.240]  So at which point does a fiction, when it's sufficiently useful and effective and improving\n",
            "[25:34.240 --> 25:40.880]  the global quality of life, does it become like accepted reality? Like there's a threshold,\n",
            "[25:40.880 --> 25:41.680]  which is just kind of-\n",
            "[25:41.680 --> 25:46.080]  If enough people believe it, it's like with money. You know, if you start a new cryptocurrency,\n",
            "[25:46.080 --> 25:51.360]  if you're the only one that believes the story, I mean, again, cryptocurrencies, you have the math,\n",
            "[25:51.360 --> 25:56.880]  of course, but ultimately it's storytelling. You're selling people a story. If nobody believes\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"English\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "output_format = 'all' #@param ['txt', 'vtt', 'srt', 'tsv', 'json', 'all']\n",
        "#@markdown > Type of file to generate to record the transcription.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ### **Optional: Fine tunning**\n",
        "#@markdown ---\n",
        "temperature = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to use for sampling.\n",
        "#@markdown ---\n",
        "temperature_increment_on_fallback = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "#@markdown ---\n",
        "best_of = 5 #@param {type:\"integer\"}\n",
        "#@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "#@markdown ---\n",
        "beam_size = 8 #@param {type:\"integer\"}\n",
        "#@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "#@markdown ---\n",
        "patience = 1.0 #@param {type:\"number\"}\n",
        "#@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "#@markdown ---\n",
        "length_penalty = -0.05 #@param {type:\"slider\", min:-0.05, max:1, step:0.05}\n",
        "#@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "#@markdown ---\n",
        "suppress_tokens = \"-1\" #@param {type:\"string\"}\n",
        "#@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "#@markdown ---\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Optional text to provide as a prompt for the first window.\n",
        "#@markdown ---\n",
        "condition_on_previous_text = True #@param {type:\"boolean\"}\n",
        "#@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "#@markdown ---\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown > whether to perform inference in fp16.\n",
        "#@markdown ---\n",
        "compression_ratio_threshold = 2.4 #@param {type:\"number\"}\n",
        "#@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "logprob_threshold = -1.0 #@param {type:\"number\"}\n",
        "#@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "no_speech_threshold = 0.6 #@param {type:\"slider\", min:-0.0, max:1, step:0.05}\n",
        "#@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        options=dict(\n",
        "            highlight_words=False,\n",
        "            max_line_count=None,\n",
        "            max_line_width=None,\n",
        "        )\n",
        "    )\n",
        "    try:\n",
        "        if output_format==\"all\":\n",
        "            for ext in ('txt', 'vtt', 'srt', 'tsv', 'json'):\n",
        "                transcript_file_name = video_path_local.stem + \".\" + ext\n",
        "                shutil.copy(\n",
        "                    video_path_local.parent / transcript_file_name,\n",
        "                    drive_whisper_path / transcript_file_name\n",
        "                )\n",
        "                display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "        else:\n",
        "            transcript_file_name = video_path_local.stem + \".\" + output_format\n",
        "            shutil.copy(\n",
        "                video_path_local.parent / transcript_file_name,\n",
        "                drive_whisper_path / transcript_file_name\n",
        "            )\n",
        "            display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "\n",
        "    except:\n",
        "        display(Markdown(f\"**Transcript file created: {transcript_local_path}**\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ad6n1m4deAHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}