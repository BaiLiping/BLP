Resources for DRL:

1. Stanford CS234
2. DeepMind David Silver
3. Berkeley Stat157
4. University of Waterloo CS885
5. [CMU 10-703](https://github.com/BaiLiping/BLP/tree/master/DRL/CMU10703)
6. [Berkeley RL Bootcamp2017](https://sites.google.com/view/deep-rl-bootcamp/lectures)
7. [OpenAI Baseline Implementation of Algs](https://github.com/openai/baselines)
8. [MorvanZhou Implementation of Algs](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow)
9. Workshop on Learning for Control (57th IEEE Conference on Decision and Control, aka CDC) [link](https://kgatsis.github.io/learning_for_control_workshop_CDC2018/)
10. Learning for Dynamics and Control (L4DC) [link](https://l4dc.mit.edu/) [videos](https://www.youtube.com/playlist?list=PLYx2nCJDi_QFrGOmIM0ale8T_1Fqu8OIF)


Books for DRL:

1. Statistical Learning (quite a lot stats concepts made its way into DRL, such as importance sampling, KL divergence, Heffoling Inequalities etc. It is a good background)
2. RL by Rich Sutton (Approximation with NN is a new development, but the overall structure of RL is still what Rich Sutton lays out in his book: Dynamic Programming->Monto Carlo->TD(0)->TD(lambda))->Tabular Methods->Q-learning->Generalization with Function Approximations->Policy Gradient->Actor-Critic with Advantage, also the distinction between on-policy learning, off-policy learning
3. [Decision Making Under Uncertainty](https://web.stanford.edu/class/aa228/cgi-bin/wp/)
4. [Algorithms for Reinforcement Learning](https://sites.ualberta.ca/~szepesva/RLBook.html)

